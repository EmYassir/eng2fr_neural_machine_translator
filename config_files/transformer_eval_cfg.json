{
  "debug": false,
  "num_examples": null,
  "num_layers": 4,
  "d_model": 512,
  "dff": 2048,
  "num_heads": 8,
  "dropout_rate": 0.1,
  "translation_batch_size": 48,
  "checkpoint_path_best": "../model/second_iteration_forward",
  "tokenizer_source_path": "tokenizer/tokenizer_en.save",
  "tokenizer_target_path": "tokenizer/tokenizer_fr.save",
  "beam_size": 7,
  "alpha": 0.6
}
